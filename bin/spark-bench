#!/usr/bin/env bash
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/../lib/spark-common.sh"

if [[ "${1:-}" == "--help" || "${1:-}" == "-h" ]]; then
    echo "Usage: spark-bench [runs] [max_tokens]"
    echo ""
    echo "Benchmark the running inference endpoint."
    echo "Works with any engine (uses OpenAI-compatible API)."
    echo ""
    echo "Arguments:"
    echo "  runs         Number of benchmark runs (default: 3)"
    echo "  max_tokens   Max tokens per response (default: 256)"
    exit 0
fi

spark_load_config

PORT="$(spark_effective_port)"
RUNS="${1:-3}"
MAX_TOKENS="${2:-256}"

# trtllm-bench.sh is generic (just curls OpenAI API), works for any engine
exec "${SPARK_TOOLS_DIR}/trtllm/trtllm-bench.sh" "${MODEL_NAME}" "${PORT}" "${RUNS}" "${MAX_TOKENS}"
